{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#Zadanie 7 (7 pkt)\n",
    "Celem zadania jest zaimplementowanie dwóch wersji naiwnego klasyfikatora Bayesa.\n",
    "* W pierwszej wersji należy dokonać dyskretyzacji danych - przedział wartości każdego atrybutu dzielimy na cztery równe przedziały i każdej ciągłej wartości atrybutu przypisujemy wartość dyskretną wynikająca z przynależności do danego przedziału.\n",
    "* W drugiej wersji wartości likelihood wyliczamy z rozkładów normalnych o średnich i odchyleniach standardowych wynikających z wartości atrybutów.\n",
    "Trening i test należy przeprowadzić dla zbioru Iris, tak jak w przypadku zadania z drzewem klasyfikacyjnym. Proszę przeprowadzić eksperymenty najpierw dla DOKŁADNIE takiego podziału zbioru testowego i treningowego jak umieszczony poniżej. W dalszej części należy przeprowadzić analizę działania klasyfikatorów dla różnych wartości parametrów. Proszę korzystać z przygotowanego szkieletu programu, oczywiście można go modyfikować według potrzeb. Wszelkie elementy szkieletu zostaną wyjaśnione na zajęciach.\n",
    "\n",
    "* Dyskretyzacja danych - **0.5 pkt**\n",
    "* Implementacja funkcji rozkładu normalnego o zadanej średniej i odchyleniu standardowym. - **0.5 pkt**\n",
    "* Implementacja naiwnego klasyfikatora Bayesa dla danych dyskretnych. - **2.0 pkt**\n",
    "* Implementacja naiwnego klasyfikatora Bayesa dla danych ciągłych. - **2.5 pkt**\n",
    "* Przeprowadzenie eksperymentów, wnioski i sposób ich prezentacji. - **1.5 pkt**"
   ],
   "metadata": {
    "id": "cpar5LziY_-0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=123)"
   ],
   "outputs": [],
   "execution_count": 134,
   "metadata": {
    "id": "XNc-O3npA-J9",
    "ExecuteTime": {
     "end_time": "2024-01-11T19:39:02.828454299Z",
     "start_time": "2024-01-11T19:39:02.794728063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([ True, False, False,  True, False, False,  True, False, False,\n        True, False, False,  True, False, False])"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test == 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T19:39:02.831306272Z",
     "start_time": "2024-01-11T19:39:02.811702634Z"
    }
   },
   "execution_count": 135
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dyskretyzacja lewostronnie domknięta"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.priors = {}\n",
    "        self.likelihoods = {}\n",
    "\n",
    "    def build_classifier(self, train_features, train_classes):\n",
    "        discrete_xtrain = self.data_discretization(train_features)\n",
    "        labels = np.unique(train_classes)\n",
    "        labels_count = Counter(train_classes)\n",
    "\n",
    "        for label in labels:\n",
    "            self.priors[label] = labels_count[label] / len(train_classes)\n",
    "\n",
    "            label_dict = {}\n",
    "            mask = train_classes == label\n",
    "            for i in range(discrete_xtrain.shape[1]):\n",
    "                attribute = discrete_xtrain[mask, i]\n",
    "                attribute_counter = Counter(attribute)\n",
    "                attribute_dict = {x: 0 for x in np.unique(discrete_xtrain)}\n",
    "                for unique_value, number in attribute_counter.items():\n",
    "                    print(number, labels_count[label])\n",
    "                    attribute_dict[unique_value] = number / labels_count[label]\n",
    "\n",
    "                label_dict[i] = attribute_dict\n",
    "            self.likelihoods[label] = label_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def data_discretization(data: np.ndarray) -> np.ndarray:\n",
    "        intervals = 4\n",
    "\n",
    "        discrete_array = np.zeros(data.shape)\n",
    "        for i in range(data.shape[1]):\n",
    "            min_value = np.min(data[:, i])\n",
    "            max_value = np.max(data[:, i])\n",
    "            interval = (max_value - min_value) / intervals\n",
    "            for j in range(data.shape[0]):\n",
    "                discrete_array[j, i] = min((data[j, i] - min_value) // interval,\n",
    "                                           intervals - 1)\n",
    "\n",
    "        return discrete_array\n",
    "\n",
    "    def predict(self, sample):\n",
    "        predictions = {}\n",
    "        for label, prior in self.priors.items():\n",
    "            value = 1\n",
    "            for i, att_value in enumerate(sample):\n",
    "                value *= self.likelihoods[label][i][att_value]\n",
    "            predictions[label] = value\n",
    "\n",
    "        return max(predictions, key=predictions.get)\n",
    "\n",
    "\n",
    "class GaussianNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.priors = {}\n",
    "        self.likelihoods = {}\n",
    "\n",
    "    def build_classifier(self, train_features, train_classes):\n",
    "        labels = np.unique(train_classes)\n",
    "        labels_count = Counter(train_classes)\n",
    "\n",
    "        for label in labels:\n",
    "            self.priors[label] = labels_count[label] / len(train_classes)\n",
    "\n",
    "            label_dict = {}\n",
    "            mask = train_classes == label\n",
    "            for i in range(train_features.shape[1]):\n",
    "                attribute = train_features[mask, i]\n",
    "                attribute_dict = {x: 0 for x in np.unique(train_features)}\n",
    "\n",
    "                attribute_mean = np.mean(attribute)\n",
    "                attribute_std = np.std(attribute)\n",
    "\n",
    "                for value in np.unique(attribute):\n",
    "                    attribute_dict[value] = self.normal_dist(value,\n",
    "                                                             attribute_mean,\n",
    "                                                             attribute_std)\n",
    "\n",
    "                label_dict[i] = attribute_dict\n",
    "            self.likelihoods[label] = label_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def normal_dist(x, mean, std):\n",
    "        prob_density = (np.pi * std) * np.exp(-0.5 * ((x - mean) / std) ** 2)\n",
    "        return prob_density\n",
    "\n",
    "    def predict(self, sample):\n",
    "        predictions = {}\n",
    "        for label, prior in self.priors.items():\n",
    "            value = 1\n",
    "            for i, att_value in enumerate(sample):\n",
    "                value *= self.likelihoods[label][i][att_value]\n",
    "            predictions[label] = value\n",
    "\n",
    "        return max(predictions, key=predictions.get)"
   ],
   "outputs": [],
   "execution_count": 136,
   "metadata": {
    "id": "fBh2tfQ44u5k",
    "ExecuteTime": {
     "end_time": "2024-01-11T19:39:02.859773514Z",
     "start_time": "2024-01-11T19:39:02.832360926Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bayes = NaiveBayes()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T19:39:02.860255035Z",
     "start_time": "2024-01-11T19:39:02.857625657Z"
    }
   },
   "execution_count": 137
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 46\n",
      "33 46\n",
      "30 46\n",
      "10 46\n",
      "5 46\n",
      "1 46\n",
      "46 46\n",
      "46 46\n",
      "27 45\n",
      "4 45\n",
      "14 45\n",
      "29 45\n",
      "11 45\n",
      "5 45\n",
      "35 45\n",
      "10 45\n",
      "31 45\n",
      "14 45\n",
      "23 44\n",
      "9 44\n",
      "11 44\n",
      "1 44\n",
      "26 44\n",
      "13 44\n",
      "5 44\n",
      "24 44\n",
      "20 44\n",
      "25 44\n",
      "19 44\n"
     ]
    }
   ],
   "source": [
    "bayes.build_classifier(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T19:39:02.860812054Z",
     "start_time": "2024-01-11T19:39:02.857845355Z"
    }
   },
   "execution_count": 138
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 0.34074074074074073, 1: 0.3333333333333333, 2: 0.32592592592592595}"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.priors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T19:39:02.873470845Z",
     "start_time": "2024-01-11T19:39:02.861359408Z"
    }
   },
   "execution_count": 139
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{0: {0: {0.0: 0.717391304347826, 1.0: 0.2826086956521739, 2.0: 0, 3.0: 0},\n  1: {0.0: 0.021739130434782608,\n   1.0: 0.21739130434782608,\n   2.0: 0.6521739130434783,\n   3.0: 0.10869565217391304},\n  2: {0.0: 1.0, 1.0: 0, 2.0: 0, 3.0: 0},\n  3: {0.0: 1.0, 1.0: 0, 2.0: 0, 3.0: 0}},\n 1: {0: {0.0: 0.08888888888888889, 1.0: 0.6, 2.0: 0.3111111111111111, 3.0: 0},\n  1: {0.0: 0.24444444444444444,\n   1.0: 0.6444444444444445,\n   2.0: 0.1111111111111111,\n   3.0: 0},\n  2: {0.0: 0, 1.0: 0.2222222222222222, 2.0: 0.7777777777777778, 3.0: 0},\n  3: {0.0: 0, 1.0: 0.3111111111111111, 2.0: 0.6888888888888889, 3.0: 0}},\n 2: {0: {0.0: 0.022727272727272728,\n   1.0: 0.20454545454545456,\n   2.0: 0.5227272727272727,\n   3.0: 0.25},\n  1: {0.0: 0.11363636363636363,\n   1.0: 0.5909090909090909,\n   2.0: 0.29545454545454547,\n   3.0: 0},\n  2: {0.0: 0, 1.0: 0, 2.0: 0.45454545454545453, 3.0: 0.5454545454545454},\n  3: {0.0: 0, 1.0: 0, 2.0: 0.4318181818181818, 3.0: 0.5681818181818182}}}"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.likelihoods"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T19:39:02.874161827Z",
     "start_time": "2024-01-11T19:39:02.871266368Z"
    }
   },
   "execution_count": 140
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1\n",
      "2 2\n",
      "2 2\n",
      "1 1\n",
      "0 0\n",
      "2 2\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "2 2\n",
      "Accuracy: 93.33%\n"
     ]
    }
   ],
   "source": [
    "x_test = bayes.data_discretization(x_test)\n",
    "positive = 0\n",
    "for data, label in zip(x_test, y_test):\n",
    "    pred = bayes.predict(data)\n",
    "    print(pred, label)\n",
    "    if pred == label:\n",
    "        positive += 1\n",
    "\n",
    "print(f\"Accuracy: {(positive/len(y_test))*100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T19:39:02.919169215Z",
     "start_time": "2024-01-11T19:39:02.873520540Z"
    }
   },
   "execution_count": 141
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T19:39:02.919531268Z",
     "start_time": "2024-01-11T19:39:02.914097891Z"
    }
   },
   "execution_count": 141
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
