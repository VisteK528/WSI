{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-28T19:32:30.736819952Z",
     "start_time": "2023-11-28T19:32:30.728707833Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "def entropy_func(class_count, num_samples):\n",
    "    probability = class_count / num_samples\n",
    "    entropy = - probability * np.log(probability)\n",
    "    return entropy\n",
    "\n",
    "def split(data, classes, split_feature, split_val):\n",
    "    dataset = np.c_[data, classes]\n",
    "    feature_column = dataset[:, split_feature].astype(float)\n",
    "    mask = feature_column >= split_val\n",
    "    \n",
    "    child_a = dataset[mask]\n",
    "    child_b = dataset[~mask]\n",
    "    child_a = np.delete(child_a, split_feature, axis=1)\n",
    "    child_b = np.delete(child_b, split_feature, axis=1)\n",
    "    return child_a, child_b\n",
    "\n",
    "class Group:\n",
    "    def __init__(self, group_classes):\n",
    "        self.group_classes = group_classes\n",
    "        self.entropy = self.group_entropy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.group_classes)\n",
    "\n",
    "    def group_entropy(self):\n",
    "        entropy = 0\n",
    "        class_counts = Counter(self.group_classes)\n",
    "        num_samples = len(self)\n",
    "        for group_class_count in class_counts.values():\n",
    "            entropy += entropy_func(group_class_count, num_samples)\n",
    "        return entropy\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, split_feature=None, split_val=None, depth=None, child_node_a=None, child_node_b=None, val=None):\n",
    "        self.split_feature = split_feature\n",
    "        self.split_val = split_val\n",
    "        self.depth = depth\n",
    "        self.child_node_a = child_node_a\n",
    "        self.child_node_b = child_node_b\n",
    "        self.val = val\n",
    "\n",
    "    def predict(self, data):\n",
    "        if self.val is not None:\n",
    "            return self.val\n",
    "        elif data[self.split_feature] > self.split_val:\n",
    "            return self.child_node_a.predict(data)\n",
    "        else:\n",
    "            return self.child_node_b.predict(data)\n",
    "\n",
    "class DecisionTreeClassifier(object):\n",
    "    def __init__(self, max_depth):\n",
    "        self.depth = 0\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_split_entropy(group_a: Group, group_b: Group):\n",
    "        split_entropy = 0\n",
    "        parent_group_count = len(group_a) + len(group_b)\n",
    "        child_groups = [group_a, group_b]\n",
    "        for group in child_groups:\n",
    "            split_entropy += (len(group) / parent_group_count) * group.group_entropy()\n",
    "        return split_entropy\n",
    "\n",
    "    def get_information_gain(self, parent_group: Group, child_group_a: Group, child_group_b: Group):\n",
    "        information_gain = parent_group.group_entropy() - self.get_split_entropy(child_group_a, child_group_b)\n",
    "        return information_gain\n",
    "\n",
    "    def get_best_feature_split(self, feature_values, classes):\n",
    "        parent = Group(classes)\n",
    "        possible_thresholds = np.unique(feature_values)\n",
    "        best_split_val = 0\n",
    "        best_gain = 0\n",
    "        \n",
    "        #print(\"Possible\", possible_thresholds)\n",
    "        for threshold in possible_thresholds:\n",
    "            child_a, child_b = split(feature_values, classes, 0, threshold)\n",
    "            if child_a.shape[0] == 0 or child_b.shape[0] == 0:\n",
    "                continue\n",
    "            child_a = Group(child_a[:, -1])\n",
    "            child_b = Group(child_b[:, -1])\n",
    "            gain = self.get_information_gain(parent, child_a, child_b)\n",
    "            \n",
    "            if gain >= best_gain:\n",
    "                best_gain = gain\n",
    "                best_split_val = threshold\n",
    "            #print(f\"Gain: {gain}\")\n",
    "        return best_split_val\n",
    "\n",
    "    def build_tree(self, data, classes, depth=0):\n",
    "        if depth == self.max_depth or len(set(classes)) == 1:\n",
    "            print(f\"Liść: {depth}\")\n",
    "            print(classes)\n",
    "            # Create a leaf node\n",
    "            #print(\"Wtf:\", set(classes))\n",
    "            return Node(val=Counter(classes).most_common(1)[0][0])\n",
    "        else:\n",
    "            print(\"Krawędź\")\n",
    "\n",
    "        best_argument = 0\n",
    "        best_split = 0\n",
    "        best_gain = 0\n",
    "        for argument in range(data.shape[1]):\n",
    "            #print(data[:, argument])\n",
    "            split_val = self.get_best_feature_split(data[:, argument], classes)\n",
    "            #split_val = np.random.choice(data[:, argument])\n",
    "            child_a, child_b = split(data, classes, argument, split_val)\n",
    "            child_a = Group(child_a[:, -1])\n",
    "            child_b = Group(child_b[:, -1])\n",
    "            gain = self.get_information_gain(Group(classes), child_a, child_b)\n",
    "\n",
    "            if gain >= best_gain:\n",
    "                best_gain = gain\n",
    "                best_argument = argument\n",
    "                best_split = split_val\n",
    "        \n",
    "        print(f\"Depth: {depth}\\t Best argument: {best_argument}\\tBest gain: {best_gain}\\tBest split: {best_split}\")\n",
    "        #print(\"Officially best: \", best_argument)\n",
    "        child_a_data, child_b_data = split(data, classes, best_argument, best_split)\n",
    "        child_a_classes = child_a_data[:, -1]\n",
    "        child_b_classes = child_b_data[:, -1]\n",
    "        \n",
    "        #print(f\"Child: {child_a_data.shape[1]}\")\n",
    "        child_a_node = self.build_tree(child_a_data[:, :-1], child_a_classes, depth + 1)\n",
    "        child_b_node = self.build_tree(child_b_data[:, :-1], child_b_classes, depth + 1)\n",
    "\n",
    "        return Node(split_feature=best_argument, split_val=best_split, depth=depth, child_node_a=child_a_node, child_node_b=child_b_node)\n",
    "\n",
    "    def fit(self, data, classes):\n",
    "        self.tree = self.build_tree(data, classes)\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.tree.predict(data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T20:16:50.598650758Z",
     "start_time": "2023-11-28T20:16:50.554665126Z"
    }
   },
   "id": "2d6b33654217cb9d"
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krawędź\n",
      "Depth: 0\t Best argument: 3\tBest gain: 0.6415255847742902\tBest split: 1.0\n",
      "Krawędź\n",
      "Depth: 1\t Best argument: 2\tBest gain: 0.4778281371342904\tBest split: 4.9\n",
      "Krawędź\n",
      "Depth: 2\t Best argument: 1\tBest gain: 0.023682627817320306\tBest split: 3.2\n",
      "Liść: 3\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "Krawędź\n",
      "Depth: 3\t Best argument: 0\tBest gain: 0.024469005380044817\tBest split: 7.1\n",
      "Liść: 4\n",
      "[2. 2. 2. 2. 2. 2. 2.]\n",
      "Liść: 4\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2.\n",
      " 1.]\n",
      "Krawędź\n",
      "Depth: 2\t Best argument: 0\tBest gain: 0.04599913566448613\tBest split: 5.0\n",
      "Krawędź\n",
      "Depth: 3\t Best argument: 0\tBest gain: 0.015659677412709155\tBest split: 2.9\n",
      "Liść: 4\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Liść: 4\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2.]\n",
      "Krawędź\n",
      "Depth: 3\t Best argument: 0\tBest gain: 0.6931471805599453\tBest split: 2.5\n",
      "Liść: 4\n",
      "[2.]\n",
      "Liść: 4\n",
      "[1.]\n",
      "Liść: 1\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Accuracy: 0.9333333333333333%\n",
      "[1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "dc = DecisionTreeClassifier(4)\n",
    "dc.fit(x_train, y_train)\n",
    "good = 0\n",
    "samples = 0\n",
    "for sample, gt in zip(x_test, y_test):\n",
    "    prediction = dc.predict(sample)\n",
    "    if prediction == gt:\n",
    "        good += 1\n",
    "    samples += 1\n",
    "\n",
    "accuracy = (good/samples)\n",
    "print(f\"Accuracy: {accuracy:<2}%\")\n",
    "print([dc.predict(sample) for sample in x_test])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T20:16:59.617236754Z",
     "start_time": "2023-11-28T20:16:59.572171319Z"
    }
   },
   "id": "44d2baa41fd2e36a"
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "data": {
      "text/plain": "2.0"
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.predict(x_test[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T20:11:32.524434265Z",
     "start_time": "2023-11-28T20:11:32.517545865Z"
    }
   },
   "id": "90db05c7103f8d00"
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T20:11:34.190124699Z",
     "start_time": "2023-11-28T20:11:34.182856920Z"
    }
   },
   "id": "ddd8e5e43099772"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d4b692c18fcfae20"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
